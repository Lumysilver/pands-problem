Summary 

R.A. Fisher published the first report on the iris data set in the Annals of Human Genetics in 1936. It is a collection of 50 samples collected by the author on each of three Irises species: setosa, versicolor, and virginica. Four attributes of 50 flowers from each of the plants were measured: sepal length, sepal width, petal length, and petal width. According to the author, the lengths and widths of the petal and sepal are features that can be utilized to determine which species they belong to using a linear discriminant model. The linear discriminant model, a statistical, machine learning, and pattern recognition technique used to distinguish between two or more objects, classes, or events, was created by Fischer himself. (Wikipedia, n.d.) 
Fischer recorded the findings for the three species in a table containing each of the four measurements, followed by tables of observed means, sums of squares, and other statistics to show how each species could be distinguished from the others. Fischer uses sums of squares and products of deviations from each mean to produce a linear function that best distinguishes between the two species. The ANOVA test is a strong statistical method for determining correlations (such as differences) between variables by comparing the means of the variables. (statisticssolutions.com, n.d.)

More about the Iris data set and its outcomes




References:

1. documenting about the existing data libraries: https://towardsdatascience.com/top-10-python-libraries-for-data-science-cd82294ec266
2. Different types of 3D libraries for Python: http://brainstormingbox.org/top-python-libraries-for-3d-machine-learning/
3. Installed Anaconda  
4. documenting on working with csv files:  https://www.analyticsvidhya.com/blog/2021/08/python-tutorial-working-with-csv-file-for-data-science/
5. Exploratory data analysis: https://medium.com/@avulurivenkatasaireddy/exploratory-data-analysis-of-iris-data-set-using-python-823e54110d2d
6. Researching different types of plots: https://www.machinelearningplus.com/plots/top-50-matplotlib-visualizations-the-master-plots-python/
7. 3D Scatter plot: https://www.kaggle.com/code/imdevskp/plotly-express-3d-scatter-plot-iris-data/notebook
8. CSV files in data science: https://www.analyticsvidhya.com/blog/2021/08/python-tutorial-working-with-csv-file-for-data-science/






***

PROJECT
Programing and Scripting
Due: last commit on before April 29th, 2022.


This project concerns the well-known Fisher’s Iris data set [3]. You must research the data set and write documentation and code (in Python [1]) to investigate it. An online search for information on the data set will convince you that many people have investigated it previously. 

You are expected to be able to break this project into several smaller tasks that are easier to solve, and to plug these together after they have been completed.
You might do that for this project as follows:

1. Research the data set online and write a summary about it in your README.
2. Download the data set and add it to your repository.
3. Write a program called analysis.py that:
1. Outputs a summary of each variable to a single text file,
2. Saves a histogram of each variable to png files, and
3. Outputs a scatter plot of each pair of variables.
4. Performs any other analysis you think is appropriate

You may produce a Jupyter notebook as well containing all your comment. This notebook should only contain text that you have written yourself, (it may contain referenced code from other sources). I will harshly mark any text (not code) that I feel is not written directly by you. I want to know what YOU think, not some third party.
It might help to suppose that your manager has asked you to investigate the data set, with a view to explaining it to your colleagues. Imagine that you are to give a presentation on the data set in a few weeks’ time, where you explain what investigating a data set entails and how Python can be used to do it. You have not been asked to create a deck of presentation slides, but rather to present your code and its output to them.
2 | P a g e Programming and Scripting Project

Minimum Viable Project
The minimum standard is a GitHub repository containing a README, a Python script, a generated summary text file, and images. The README (and/or notebook) should contain a summary of the data set and your investigations into it. It should also clearly document how to run the Python code and what that code does. Furthermore, it should list all references used in completing the project.
A better project will be well organised and contain detailed explanations. The analysis will be well conceived, and examples of interesting analyses that others have pursued based on the data set will be discussed. Note that the point of this project is to use Python. You may use any Python libraries that you wish, whether they have been discussed in class or not. You should not be thinking of using spreadsheet software like Excel to do your calculations.

Submissions
Create a repository called pands-project on GitHub (this is the third repository that I have asked you to create after my-work and pands-problem-sheet).
Please copy a link to this repository in the project assessment I set up on learnonline. Please do not put any other text into this assessment apart from the link to the URL. I suggest that you copy the link, you can of course continue to commit and push to this repository after you have copied the link.
I will correct what is in your pands-project repository (only), So use GitHub to manage your project submission.
It is expected that your repository will have lots of commits, with each commit relating to a reasonably small unit of work.

In the last week of term, or at any other time, you may be asked to explain the contents of your git repository. While it is encouraged that students will engage in peer learning, any unreferenced documentation and software that is contained in your submission must have been written by you. You can show this by having an incremental commit history and by being able to explain your code.


***